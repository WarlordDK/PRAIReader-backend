import os
import torch
from transformers import pipeline
from typing import Dict, Any, List
from core.config import get_hf_token
import asyncio
import re


class TextAnalyzer:
    def __init__(self):
        self.hf_token = get_hf_token()
        self.model = None
        self.models_initialized = False

    async def initialize_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        if self.models_initialized:
            return

        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")

        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ª–µ–Ω—å–∫—É—é –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
            self.model = pipeline(
                "text-generation",
                model="distilgpt2",  # –ù–∞–¥–µ–∂–Ω–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
                device="cpu",
                torch_dtype=torch.float32,
            )

            self.models_initialized = True
            print("‚úÖ –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {e}")
            self.models_initialized = False

    def analyze_text(self, text: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å–ª–∞–π–¥–∞"""
        if not self.models_initialized:
            return self._get_fallback_analysis(text)

        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫
            short_text = text[:300]

            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç—ã –æ—Ç LLM
            analysis = self._get_llm_analysis(short_text)
            recommendations = self._get_llm_recommendations(short_text)
            problems = self._get_llm_problems(short_text)

            return {
                "main_topic": self._extract_main_topic(text),
                "key_points": self._extract_key_points(text),
                "clarity_score": self._calculate_clarity_score(text),
                "structure_quality": self._assess_structure(text),
                "specific_recommendations": recommendations,
                "problems_detected": problems,
                "llm_analysis": analysis,
                "analysis_type": "llm_enhanced"
            }

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞: {e}")
            return self._get_fallback_analysis(text)

    def _get_llm_analysis(self, text: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç LLM"""
        prompt = f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç —Å–ª–∞–π–¥–∞: '{text}'. –û—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏:"
        return self._safe_llm_call(prompt, 80)

    def _get_llm_recommendations(self, text: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –æ—Ç LLM"""
        prompt = f"–î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–µ–∫—Å—Ç—É —Å–ª–∞–π–¥–∞: '{text}'. –°–æ–≤–µ—Ç—ã:"
        response = self._safe_llm_call(prompt, 60)
        return self._parse_list_response(response, "–£–ª—É—á—à–∏—Ç–µ —è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è")

    def _get_llm_problems(self, text: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º –æ—Ç LLM"""
        prompt = f"–ö–∞–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ —Ç–µ–∫—Å—Ç–µ —Å–ª–∞–π–¥–∞: '{text}'? –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:"
        response = self._safe_llm_call(prompt, 60)
        return self._parse_list_response(response, "–ü—Ä–æ–±–ª–µ–º—ã –Ω–µ –≤—ã—è–≤–ª–µ–Ω—ã")

    def _safe_llm_call(self, prompt: str, max_tokens: int) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–∑–æ–≤ LLM"""
        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º—Ç–∞
            if len(prompt) > 500:
                prompt = prompt[:500]

            response = self.model(
                prompt,
                max_new_tokens=max_tokens,
                num_return_sequences=1,
                temperature=0.7,
                do_sample=True,
                pad_token_id=50256,
                truncation=True
            )

            if response and len(response) > 0:
                generated_text = response[0]['generated_text']
                # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
                if prompt in generated_text:
                    return generated_text.replace(prompt, "").strip()
                return generated_text[:150].strip()  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞
            return ""

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ LLM call: {e}")
            return ""

    def _parse_list_response(self, response: str, default: str) -> List[str]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –≤ —Å–ø–∏—Å–æ–∫"""
        if not response:
            return [default]

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—É–Ω–∫—Ç—ã
        lines = [line.strip() for line in response.split('.') if line.strip()]
        items = []

        for line in lines:
            clean_line = re.sub(r'^[\d\-‚Ä¢*]\s*', '', line).strip()
            if clean_line and len(clean_line) > 10 and len(clean_line) < 100:
                items.append(clean_line)

        return items[:2] if items else [default]

    def _extract_main_topic(self, text: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–º—ã"""
        sentences = [s.strip() for s in text.split('.') if s.strip()]
        if sentences:
            first_sentence = sentences[0]
            words = first_sentence.split()[:5]
            return ' '.join(words) + ('...' if len(first_sentence) > len(' '.join(words)) else '')
        return "–¢–µ–º–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"

    def _extract_key_points(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–æ–≤"""
        sentences = [s.strip() for s in text.split('.') if s.strip() and len(s.strip()) > 8]
        return sentences[:2] if sentences else ["–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ —Ç–µ–∫—Å—Ç–µ"]

    def _calculate_clarity_score(self, text: str) -> int:
        """–û—Ü–µ–Ω–∫–∞ —è—Å–Ω–æ—Å—Ç–∏"""
        words = text.split()
        sentences = [s for s in text.split('.') if s.strip()]

        if not sentences:
            return 3

        avg_length = len(words) / len(sentences)

        if 10 <= avg_length <= 25:
            return 8
        elif 5 <= avg_length < 10 or 25 < avg_length <= 35:
            return 6
        else:
            return 4

    def _assess_structure(self, text: str) -> str:
        """–û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        sentences = [s for s in text.split('.') if s.strip()]
        if len(sentences) >= 3:
            return "—Ö–æ—Ä–æ—à–∞—è"
        elif len(sentences) >= 2:
            return "–±–∞–∑–æ–≤–∞—è"
        else:
            return "–º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è"

    def _get_fallback_analysis(self, text: str) -> Dict[str, Any]:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        return {
            "main_topic": self._extract_main_topic(text),
            "key_points": self._extract_key_points(text),
            "clarity_score": self._calculate_clarity_score(text),
            "structure_quality": self._assess_structure(text),
            "specific_recommendations": ["–î–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ ML –º–æ–¥–µ–ª—å"],
            "problems_detected": ["–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –≤ –±–∞–∑–æ–≤–æ–º —Ä–µ–∂–∏–º–µ"],
            "llm_analysis": "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞",
            "analysis_type": "fallback"
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
text_analyzer = TextAnalyzer()